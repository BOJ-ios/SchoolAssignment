{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QklLFdrtjr5a"
   },
   "source": [
    "### 패키지 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7lV8TMctTuX7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Languages\\anaconda3\\envs\\ML\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 지정된 프로시저를 찾을 수 없습니다'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wglW_lW5j8RM"
   },
   "source": [
    "## Dataset 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "24F1ZKZ9j2y-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Training dataset 다운로드\n",
    "cifar100_train = dataset.CIFAR100(root = \"./\",\n",
    "                            train = True,\n",
    "                            transform = transform.ToTensor(),\n",
    "                            download = True)\n",
    "# Testing dataset 다운로드\n",
    "cifar100_test = dataset.CIFAR100(root = \"./\",\n",
    "                            train = False,\n",
    "                            transform = transform.ToTensor(),\n",
    "                            download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I65fUdO7uzp-"
   },
   "source": [
    "## 신경망 모델 정의\n",
    "- Fully Connected Layer -> nn.Linear(in_features, out_features)\n",
    "- Convolutional Layer -> nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "- ReLU -> nn.ReLU()\n",
    "- Max Pooling -> nn.MaxPool2d(kernel_size, stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "oc4HgDKRtDFk"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(Network, self).__init__()\n",
    "\n",
    "    # 신경망 파라미터 초기화 (Conv, FC, ReLU, MaxPool)\n",
    "    self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1_1 = nn.BatchNorm2d(16)\n",
    "    self.conv1_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1_2 = nn.BatchNorm2d(32)  \n",
    "    self.conv2_1 = nn.Conv2d(in_channels=32, out_channels=48, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2_1 = nn.BatchNorm2d(48)\n",
    "    self.conv2_2 = nn.Conv2d(in_channels=48, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2_2 = nn.BatchNorm2d(64)\n",
    "    self.conv3_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn3_1 = nn.BatchNorm2d(128)\n",
    "    self.conv3_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn3_2 = nn.BatchNorm2d(256)\n",
    "    self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn4_1 = nn.BatchNorm2d(384)\n",
    "    self.conv4_2 = nn.Conv2d(in_channels=384, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn4_2 = nn.BatchNorm2d(512)\n",
    "    \n",
    "    # Initialize fully connected layers\n",
    "    self.fc1 = nn.Linear(in_features=2048, out_features=1024)\n",
    "    self.fc2 = nn.Linear(in_features=1024, out_features=512)\n",
    "    self.fc3 = nn.Linear(in_features=512, out_features=256)\n",
    "    self.fc4 = nn.Linear(in_features=256, out_features=100)\n",
    "\n",
    "    # Max pooling\n",
    "    self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    # Activation\n",
    "    self.relu = nn.ReLU()\n",
    "    \n",
    "    # Skip connection* 위한 convolution layer 추가 선언\n",
    "    self.conv_skip1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv_skip2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv_skip3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv_skip4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    skip_y = self.conv_skip1(x)\n",
    "    y = self.relu(self.bn1_1(self.conv1_1(x)))\n",
    "    y = self.relu(self.bn1_2(self.conv1_2(y)))\n",
    "    y = y + skip_y\n",
    "    y = self.max_pool(y)\n",
    "    \n",
    "    skip_y = self.conv_skip2(y)\n",
    "    y = self.relu(self.bn2_1(self.conv2_1(y)))\n",
    "    y = self.relu(self.bn2_2(self.conv2_2(y)))\n",
    "    y = y + skip_y\n",
    "    y = self.max_pool(y)\n",
    "    \n",
    "    skip_y = self.conv_skip3(y)\n",
    "    y = self.relu(self.bn3_1(self.conv3_1(y)))\n",
    "    y = self.relu(self.bn3_2(self.conv3_2(y)))\n",
    "    y = y + skip_y\n",
    "    y = self.max_pool(y)\n",
    "    \n",
    "    skip_y = self.conv_skip4(y)\n",
    "    y = self.relu(self.bn4_1(self.conv4_1(y)))\n",
    "    y = self.relu(self.bn4_2(self.conv4_2(y)))\n",
    "    y = y + skip_y\n",
    "    y = self.max_pool(y)\n",
    "    \n",
    "    # Flatten feature maps\n",
    "    y = y.view(-1, 2048)\n",
    "\n",
    "    # Fully connected layers with dropout in between\n",
    "    y = self.relu(self.fc1(y))\n",
    "    y = self.relu(self.fc2(y))\n",
    "    y = self.relu(self.fc3(y))\n",
    "    y = self.fc4(y)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Fz63UdivjY3"
   },
   "source": [
    "## Hyper-parameters 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "DIdnVvA4vjCe"
   },
   "outputs": [],
   "source": [
    "batch_size = 100     # 고정 하이퍼 파라미터\n",
    "training_epochs = 30 # 고정 하이퍼 파라미터\n",
    "\n",
    "learning_rate = 0.01\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "network = Network().to('cuda')\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr = learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "data_loader = DataLoader(dataset=cifar100_train,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBPBa7th2oNx"
   },
   "source": [
    "## CNN 학습을 위한 반복문 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "_vKcxUMlvUJE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss = 3.797328\n",
      "Epoch: 2 Loss = 2.765502\n",
      "Epoch: 3 Loss = 2.195975\n",
      "Epoch: 4 Loss = 1.795580\n",
      "Epoch: 5 Loss = 1.447281\n",
      "Epoch: 6 Loss = 1.133775\n",
      "Epoch: 7 Loss = 0.850002\n",
      "Epoch: 8 Loss = 0.615856\n",
      "Epoch: 9 Loss = 0.469003\n",
      "Epoch: 10 Loss = 0.346396\n",
      "Epoch: 11 Loss = 0.276044\n",
      "Epoch: 12 Loss = 0.232010\n",
      "Epoch: 13 Loss = 0.188048\n",
      "Epoch: 14 Loss = 0.158816\n",
      "Epoch: 15 Loss = 0.134752\n",
      "Epoch: 16 Loss = 0.112392\n",
      "Epoch: 17 Loss = 0.094978\n",
      "Epoch: 18 Loss = 0.086762\n",
      "Epoch: 19 Loss = 0.076946\n",
      "Epoch: 20 Loss = 0.068027\n",
      "Epoch: 21 Loss = 0.061557\n",
      "Epoch: 22 Loss = 0.058384\n",
      "Epoch: 23 Loss = 0.053574\n",
      "Epoch: 24 Loss = 0.052377\n",
      "Epoch: 25 Loss = 0.051170\n",
      "Epoch: 26 Loss = 0.038249\n",
      "Epoch: 27 Loss = 0.037341\n",
      "Epoch: 28 Loss = 0.041728\n",
      "Epoch: 29 Loss = 0.048347\n",
      "Epoch: 30 Loss = 0.038000\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "  network.train()\n",
    "  avg_cost = 0\n",
    "  total_batch = len(data_loader)\n",
    "  \n",
    "  for img, label in data_loader:\n",
    "    img = img.to('cuda')\n",
    "    label = label.to('cuda')\n",
    "    pred = network(img)\n",
    "    loss = loss_function(pred, label)\n",
    "    optimizer.zero_grad() # gradient 초기화\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    avg_cost += loss / total_batch\n",
    "\n",
    "  print('Epoch: %d Loss = %f'%(epoch+1, avg_cost))\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-ewxZmlAPZ1"
   },
   "source": [
    "## 학습이 완료된 모델을 이용해 정답률 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "ae3-hzD67GG5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5083000063896179\n"
     ]
    }
   ],
   "source": [
    "network.eval()\n",
    "network = network.to('cpu')\n",
    "img_test = torch.tensor(np.transpose(cifar100_test.data,(0,3,1,2))) / 255.\n",
    "label_test = torch.tensor(cifar100_test.targets)\n",
    "\n",
    "with torch.no_grad(): # test에서는 기울기 계산 제외\n",
    "  prediction = network(img_test) # 전체 test data를 한번에 계산\n",
    "\n",
    "  correct_prediction = torch.argmax(prediction, 1) == label_test\n",
    "  accuracy = correct_prediction.float().mean()\n",
    "  print('Accuracy:', accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1UiV9LAqa5SX190TsRvE1OfNPCJbc03zp",
     "timestamp": 1667979764680
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
