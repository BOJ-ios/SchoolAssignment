{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QklLFdrtjr5a"
   },
   "source": [
    "### 패키지 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7lV8TMctTuX7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wglW_lW5j8RM"
   },
   "source": [
    "## Dataset 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "24F1ZKZ9j2y-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169001437/169001437 [11:55<00:00, 236093.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-100-python.tar.gz to ./\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Training dataset 다운로드\n",
    "cifar100_train = dataset.CIFAR100(root = \"./\",\n",
    "                            train = True,\n",
    "                            transform = transform.ToTensor(),\n",
    "                            download = True)\n",
    "# Testing dataset 다운로드\n",
    "cifar100_test = dataset.CIFAR100(root = \"./\",\n",
    "                            train = False,\n",
    "                            transform = transform.ToTensor(),\n",
    "                            download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I65fUdO7uzp-"
   },
   "source": [
    "## 신경망 모델 정의\n",
    "- Fully Connected Layer -> nn.Linear(in_features, out_features)\n",
    "- Convolutional Layer -> nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "- ReLU -> nn.ReLU()\n",
    "- Max Pooling -> nn.MaxPool2d(kernel_size, stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oc4HgDKRtDFk"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(Network, self).__init__()\n",
    "\n",
    "    # 신경망 파라미터 초기화 (Conv, FC, ReLU, MaxPool)\n",
    "    self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1_1 = nn.BatchNorm2d(16)\n",
    "    self.conv1_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1_2 = nn.BatchNorm2d(32)  \n",
    "    self.conv2_1 = nn.Conv2d(in_channels=32, out_channels=48, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2_1 = nn.BatchNorm2d(48)\n",
    "    self.conv2_2 = nn.Conv2d(in_channels=48, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2_2 = nn.BatchNorm2d(64)\n",
    "    self.conv3_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn3_1 = nn.BatchNorm2d(128)\n",
    "    self.conv3_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn3_2 = nn.BatchNorm2d(256)\n",
    "    self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn4_1 = nn.BatchNorm2d(384)\n",
    "    self.conv4_2 = nn.Conv2d(in_channels=384, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn4_2 = nn.BatchNorm2d(512)\n",
    "    \n",
    "    # Initialize fully connected layers\n",
    "    self.fc1 = nn.Linear(in_features=2048, out_features=1024)\n",
    "    self.fc2 = nn.Linear(in_features=1024, out_features=512)\n",
    "    self.fc3 = nn.Linear(in_features=512, out_features=256)\n",
    "    self.fc4 = nn.Linear(in_features=256, out_features=100)\n",
    "\n",
    "    # Max pooling\n",
    "    self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    # Activation\n",
    "    self.relu = nn.ReLU()\n",
    "    \n",
    "    # Skip connection* 위한 convolution layer 추가 선언\n",
    "    self.conv_skip1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv_skip2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv_skip3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv_skip4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    skip_y = self.conv_skip1(x)\n",
    "    y = self.relu(self.bn1_1(self.conv1_1(x)))\n",
    "    y = self.relu(self.bn1_2(self.conv1_2(y)))\n",
    "    y = y + skip_y\n",
    "    y = self.max_pool(y)\n",
    "    \n",
    "    skip_y = self.conv_skip2(y)\n",
    "    y = self.relu(self.bn2_1(self.conv2_1(y)))\n",
    "    y = self.relu(self.bn2_2(self.conv2_2(y)))\n",
    "    y = y + skip_y\n",
    "    y = self.max_pool(y)\n",
    "    \n",
    "    skip_y = self.conv_skip3(y)\n",
    "    y = self.relu(self.bn3_1(self.conv3_1(y)))\n",
    "    y = self.relu(self.bn3_2(self.conv3_2(y)))\n",
    "    y = y + skip_y\n",
    "    y = self.max_pool(y)\n",
    "    \n",
    "    skip_y = self.conv_skip4(y)\n",
    "    y = self.relu(self.bn4_1(self.conv4_1(y)))\n",
    "    y = self.relu(self.bn4_2(self.conv4_2(y)))\n",
    "    y = y + skip_y\n",
    "    y = self.max_pool(y)\n",
    "    \n",
    "    # Flatten feature maps\n",
    "    y = y.view(-1, 2048)\n",
    "\n",
    "    # Fully connected layers with dropout in between\n",
    "    y = self.relu(self.fc1(y))\n",
    "    y = self.relu(self.fc2(y))\n",
    "    y = self.relu(self.fc3(y))\n",
    "    y = self.fc4(y)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Fz63UdivjY3"
   },
   "source": [
    "## Hyper-parameters 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DIdnVvA4vjCe"
   },
   "outputs": [],
   "source": [
    "batch_size = 100     # 고정 하이퍼 파라미터\n",
    "training_epochs = 30 # 고정 하이퍼 파라미터\n",
    "\n",
    "learning_rate = 0.01\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# network = Network().to('cuda')\n",
    "network = Network().to('cpu')\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr = learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "data_loader = DataLoader(dataset=cifar100_train,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBPBa7th2oNx"
   },
   "source": [
    "## CNN 학습을 위한 반복문 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_vKcxUMlvUJE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss = 3.753700\n",
      "Epoch: 2 Loss = 2.729377\n",
      "Epoch: 3 Loss = 2.160750\n",
      "Epoch: 4 Loss = 1.769590\n",
      "Epoch: 5 Loss = 1.423618\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LoewllZoe\\Documents\\GitHub\\SchoolAssignment\\머신러닝\\231116_Basecode_Simplified_VGG_CIFAR10\\김민규_1924385_머신러닝_실습리포트.ipynb 셀 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LoewllZoe/Documents/GitHub/SchoolAssignment/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/231116_Basecode_Simplified_VGG_CIFAR10/%EA%B9%80%EB%AF%BC%EA%B7%9C_1924385_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%8B%A4%EC%8A%B5%EB%A6%AC%ED%8F%AC%ED%8A%B8.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(pred, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LoewllZoe/Documents/GitHub/SchoolAssignment/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/231116_Basecode_Simplified_VGG_CIFAR10/%EA%B9%80%EB%AF%BC%EA%B7%9C_1924385_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%8B%A4%EC%8A%B5%EB%A6%AC%ED%8F%AC%ED%8A%B8.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad() \u001b[39m# gradient 초기화\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/LoewllZoe/Documents/GitHub/SchoolAssignment/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/231116_Basecode_Simplified_VGG_CIFAR10/%EA%B9%80%EB%AF%BC%EA%B7%9C_1924385_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%8B%A4%EC%8A%B5%EB%A6%AC%ED%8F%AC%ED%8A%B8.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LoewllZoe/Documents/GitHub/SchoolAssignment/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/231116_Basecode_Simplified_VGG_CIFAR10/%EA%B9%80%EB%AF%BC%EA%B7%9C_1924385_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%8B%A4%EC%8A%B5%EB%A6%AC%ED%8F%AC%ED%8A%B8.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LoewllZoe/Documents/GitHub/SchoolAssignment/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/231116_Basecode_Simplified_VGG_CIFAR10/%EA%B9%80%EB%AF%BC%EA%B7%9C_1924385_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%8B%A4%EC%8A%B5%EB%A6%AC%ED%8F%AC%ED%8A%B8.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m avg_cost \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss \u001b[39m/\u001b[39m total_batch\n",
      "File \u001b[1;32mc:\\Users\\LoewllZoe\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LoewllZoe\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "  network.train()\n",
    "  avg_cost = 0\n",
    "  total_batch = len(data_loader)\n",
    "  \n",
    "  for img, label in data_loader:\n",
    "    # img = img.to('cuda')\n",
    "    # label = label.to('cuda')\n",
    "    img = img.to('cpu')\n",
    "    label = label.to('cpu')\n",
    "    pred = network(img)\n",
    "    loss = loss_function(pred, label)\n",
    "    optimizer.zero_grad() # gradient 초기화\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    avg_cost += loss / total_batch\n",
    "\n",
    "  print('Epoch: %d Loss = %f'%(epoch+1, avg_cost))\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-ewxZmlAPZ1"
   },
   "source": [
    "## 학습이 완료된 모델을 이용해 정답률 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "ae3-hzD67GG5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5083000063896179\n"
     ]
    }
   ],
   "source": [
    "network.eval()\n",
    "network = network.to('cpu')\n",
    "img_test = torch.tensor(np.transpose(cifar100_test.data,(0,3,1,2))) / 255.\n",
    "label_test = torch.tensor(cifar100_test.targets)\n",
    "\n",
    "with torch.no_grad(): # test에서는 기울기 계산 제외\n",
    "  prediction = network(img_test) # 전체 test data를 한번에 계산\n",
    "\n",
    "  correct_prediction = torch.argmax(prediction, 1) == label_test\n",
    "  accuracy = correct_prediction.float().mean()\n",
    "  print('Accuracy:', accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1UiV9LAqa5SX190TsRvE1OfNPCJbc03zp",
     "timestamp": 1667979764680
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
